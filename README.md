# Delay Forecast â€” POC MLOps

POC de prÃ©diction des retards de train en fonction de la mÃ©tÃ©o (et contexte : trafic, jours fÃ©riÃ©s).

## Stack
Airflow â€¢ MLflow â€¢ FastAPI â€¢ Docker Compose â€¢ GitHub Actions â€¢ Neon Postgres â€¢ S3

---

## ğŸš€ Run local

```bash
# PremiÃ¨re installation uniquement (si .env n'existe pas)
cp .env.example .env
# Puis renseigner les variables (voir section Configuration)
make up
```

### URLs des services

| Service | URL | Description |
|---------|-----|-------------|
| Airflow | http://localhost:8080 | Orchestration des pipelines (admin/admin) |
| MLflow | http://localhost:5000 | Tracking des expÃ©riences ML |
| API | http://localhost:8000 | API de prÃ©diction |
| API Docs | http://localhost:8000/docs | Documentation Swagger |

### Commandes utiles

```bash
make up       # DÃ©marrer tous les services
make down     # ArrÃªter et supprimer les conteneurs
make logs     # Voir les logs en temps rÃ©el
make ps       # Ã‰tat des conteneurs
make rebuild  # Reconstruire les images sans cache
```

---

## ğŸ”§ Configuration

### GÃ©nÃ©rer les clÃ©s Airflow

```bash
# AIRFLOW_FERNET_KEY (chiffrement des secrets)
python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# AIRFLOW_WEBSERVER_SECRET_KEY (sessions web)
python -c "import secrets; print(secrets.token_urlsafe(32))"
```

---

## ğŸ“Š MLflow â€” Guide d'utilisation

### AccÃ¨s

- **Interface Web** : http://localhost:5000
- **Tracking URI (depuis les conteneurs)** : `http://mlflow:5000`
- **Tracking URI (depuis l'hÃ´te)** : `http://localhost:5000`

### Connexion depuis Python

```python
import mlflow

# Configurer la connexion
mlflow.set_tracking_uri("http://mlflow:5000")  # Depuis un conteneur Docker
# mlflow.set_tracking_uri("http://localhost:5000")  # Depuis l'hÃ´te

# CrÃ©er ou sÃ©lectionner une expÃ©rience
mlflow.set_experiment("delay-forecast")
```

### Logger un entraÃ®nement

```python
import mlflow
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np

mlflow.set_tracking_uri("http://mlflow:5000")
mlflow.set_experiment("delay-forecast")

with mlflow.start_run(run_name="linear-regression-v1"):
    # ParamÃ¨tres
    mlflow.log_param("model_type", "LinearRegression")
    mlflow.log_param("features", ["temperature", "rain_mm", "wind_kmh"])
    
    # EntraÃ®nement
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    # MÃ©triques
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mlflow.log_metric("rmse", rmse)
    mlflow.log_metric("r2", model.score(X_test, y_test))
    
    # Sauvegarder le modÃ¨le
    mlflow.sklearn.log_model(
        model, 
        "model",
        registered_model_name="delay-forecast-model"
    )
```

### Charger un modÃ¨le (dans l'API)

```python
import mlflow

# Charger la derniÃ¨re version en Production
model = mlflow.sklearn.load_model("models:/delay-forecast-model/Production")

# Ou une version spÃ©cifique
model = mlflow.sklearn.load_model("models:/delay-forecast-model/1")

# Faire une prÃ©diction
prediction = model.predict([[15.0, 2.5, 20.0, 0, 0.7]])
```

### Promouvoir un modÃ¨le en Production

Via l'interface MLflow (http://localhost:5000) :
1. Aller dans **Models**
2. SÃ©lectionner le modÃ¨le `delay-forecast-model`
3. Cliquer sur une version
4. Cliquer sur **Stage** â†’ **Transition to Production**

Ou via Python :
```python
from mlflow import MlflowClient

client = MlflowClient(tracking_uri="http://mlflow:5000")
client.transition_model_version_stage(
    name="delay-forecast-model",
    version=1,
    stage="Production"
)
```

---

## ğŸ“ Structure du projet

```
delay-forecast/
â”œâ”€â”€ docker-compose.yml      # Orchestration des services
â”œâ”€â”€ Makefile                # Commandes raccourcies
â”œâ”€â”€ .env.example            # Template des variables d'environnement
â”œâ”€â”€ libs/                   # BibliothÃ¨ques partagÃ©es
â”‚   â”œâ”€â”€ db/neon.py         # Connexion Neon DB
â”‚   â””â”€â”€ storage/s3.py      # Client S3
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ dags/          # DAGs Airflow
â”‚   â”‚   â”œâ”€â”€ tasks/         # Scripts Python (ingestion, ETL, training)
â”‚   â”‚   â””â”€â”€ scripts/       # Scripts d'initialisation
â”‚   â”œâ”€â”€ api/               # API FastAPI
â”‚   â””â”€â”€ mlflow/            # (Configuration MLflow)
â””â”€â”€ .github/workflows/     # CI/CD
```

---

## ğŸ‘¥ Ã‰quipe

| ResponsabilitÃ© | Composants |
|----------------|------------|
| Infrastructure | Docker, Airflow, MLflow |
| Data Pipeline | Ingestion, ETL, Neon DB |
| ML | Training, Evidently |
| API | FastAPI, PrÃ©dictions |
